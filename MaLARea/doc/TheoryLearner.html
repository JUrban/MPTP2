<?xml version="1.0" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>TheoryLearner.pl</title>
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<link rev="made" href="mailto:root@localhost" />
</head>

<body style="background-color: white">

<p><a name="__index__"></a></p>
<!-- INDEX BEGIN -->

<ul>

	<li><a href="#name">NAME</a></li>
	<li><a href="#synopsis">SYNOPSIS</a></li>
	<li><a href="#options">OPTIONS</a></li>
	<li><a href="#description">DESCRIPTION</a></li>
	<li><a href="#contact">CONTACT</a></li>
	<li><a href="#licence">LICENCE</a></li>
</ul>
<!-- INDEX END -->

<hr />
<p>
</p>
<h1><a name="name">NAME</a></h1>
<p>TheoryLearner.pl (Script trying to solve multiple problems in large theory by learning from successes)</p>
<p>
</p>
<hr />
<h1><a name="synopsis">SYNOPSIS</a></h1>
<p>TheoryLearner.pl [options] filestem</p>
<p>time ./TheoryLearner.pl --fileprefix='chainy_lemma1/' --filepostfix='.ren' chainy1 | tee chainy1.log</p>
<pre>
 Options:
   --commonfile=&lt;arg&gt;,      -c&lt;arg&gt;
   --fileprefix=&lt;arg&gt;,      -e&lt;arg&gt;
   --filepostfix=&lt;arg&gt;,     -s&lt;arg&gt;
   --tmpdir=&lt;arg&gt;,          -T&lt;arg&gt;
   --maxcpulimit=&lt;arg&gt;,     -C&lt;arg&gt;
   --mincpulimit=&lt;arg&gt;,     -U&lt;arg&gt;
   --maxaxiomlimit=&lt;arg&gt;,   -A&lt;arg&gt;
   --permutetimelimit=&lt;arg&gt;, -P&lt;arg&gt;
   --dofull=&lt;arg&gt;,          -f&lt;arg&gt;
   --iterrecover=&lt;arg&gt;,     -I&lt;arg&gt;
   --loadprovedby=&lt;arg&gt;,    -B&lt;arg&gt;
   --runeprover=&lt;arg&gt;,      -E&lt;arg&gt;
   --runspass=&lt;arg&gt;,        -S&lt;arg&gt;
   --runvampire=&lt;arg&gt;,      -V&lt;arg&gt;
   --runparadox=&lt;arg&gt;,      -p&lt;arg&gt;
   --runmace=&lt;arg&gt;,         -M&lt;arg&gt;
   --usemodels=&lt;arg&gt;,       -D&lt;arg&gt;
   --srassemul=&lt;arg&gt;,       -R&lt;arg&gt;
   --similarity=&lt;arg&gt;,      -i&lt;arg&gt;
   --generalize=&lt;arg&gt;,      -g&lt;arg&gt;
   --parallelize=&lt;arg&gt;,     -j&lt;arg&gt;
   --iterpolicy=&lt;arg&gt;,      -y&lt;arg&gt;
   --recadvice=&lt;arg&gt;,       -a&lt;arg&gt;
   --reuseeval=&lt;arg&gt;,       -u&lt;arg&gt;
   --limittargets=&lt;arg&gt;,    -L&lt;arg&gt;
   --boostlimit=&lt;arg&gt;,      -b&lt;arg&gt;
   --boostweight=&lt;arg&gt;,     -w&lt;arg&gt;
   --refsbgcheat=&lt;arg&gt;,     -r&lt;arg&gt;
   --alwaysmizrefs=&lt;arg&gt;,   -m&lt;arg&gt;
   --help,                  -h
   --man</pre>
<p>
</p>
<hr />
<h1><a name="options">OPTIONS</a></h1>
<dl>
<dt><strong><a name="item__2d_2dcommonfile_3d_3carg_3e_2c__2dc_3carg_3e"><strong>--commonfile=&lt;arg</strong>, -c&lt;arg&gt; &gt;&gt;&gt;</a></strong></dt>

<dd>
<p>One common file containing all axioms and conjectures that should be proved 
from them. If an extra axiom is needed in this input scenario for a conjecture,
it has to be added as an antecedent of an implication. The --fileprefix
option is mandatory in this case, specifying the directory for autogenerated
problem files.</p>
</dd>
<dt><strong><a name="item__2d_2dfileprefix_3d_3carg_3e_2c__2de_3carg_3e"><strong>--fileprefix=&lt;arg</strong>, -e&lt;arg&gt; &gt;&gt;&gt;</a></strong></dt>

<dd>
<p>Prefix saying how to create problem file names from conjecture names.
It is prepended to the conjecture name (and can contain directory part ended with /).
If the --commonfile option was used, this tells the directory used for
autogenerated problem files (the directory must not exist).</p>
</dd>
<dt><strong><a name="item__2d_2dfilepostfix_3d_3carg_3e_2c__2ds_3carg_3e"><strong>--filepostfix=&lt;arg</strong>, -s&lt;arg&gt; &gt;&gt;&gt;</a></strong></dt>

<dd>
<p>Postfix saying how to create problem file names from conjecture names.
It is appended to the conjecture name (typically a file extension).</p>
</dd>
<dt><strong><a name="item__2d_2dtmpdir_3d_3carg_3e_2c__2dt_3carg_3e"><strong>--tmpdir=&lt;arg</strong>, -<strong>T</strong>&lt;arg&gt; &gt;&gt;&gt;</a></strong></dt>

<dd>
<p>Directory (slash-ended) for temporary problem and result files.
Defaults to ``'', which means no usage of any special directory.
Otherwise, the tmpdir/fileprefix directory must not previously exist.
The /tmp/ is usable, however /dev/shm/ or similar memory-based
(tmpfs) location is strongly recommended, because the number of
these files is large. After each pass, these files are tgz-ed
into a .pass_nr file, and deleted.</p>
</dd>
<dt><strong><a name="item__2d_2dmaxcpulimit_3d_3carg_3e_2c__2dc_3carg_3e"><strong>--maxcpulimit=&lt;arg</strong>, -<strong>C</strong>&lt;arg&gt; &gt;&gt;&gt;</a></strong></dt>

<dd>
<p>Upper limit to which the CPU time for one ATP attempt is grown
exponentially (multiplied by 4 and starting from 1 second base). 
The default is 16 seconds (should be power of 4)</p>
</dd>
<dt><strong><a name="item__2d_2dmincpulimit_3d_3carg_3e_2c__2du_3carg_3e"><strong>--mincpulimit=&lt;arg</strong>, -<strong>U</strong>&lt;arg&gt; &gt;&gt;&gt;</a></strong></dt>

<dd>
<p>Lower limit for the CPU time for one ATP attempt.
The default is 1 second (should be power of 4).</p>
</dd>
<dt><strong><a name="item__2d_2dmaxaxiomlimit_3d_3carg_3e_2c__2da_3carg_3e"><strong>--maxaxiomlimit=&lt;arg</strong>, -<strong>A</strong>&lt;arg&gt; &gt;&gt;&gt;</a></strong></dt>

<dd>
<p>Upper limit to which the number of axioms used for one ATP attempt is grown
exponentially (multiplied by 2 and starting from 4 axioms).
The default is 128 axioms (should be power of 2).</p>
</dd>
<dt><strong><a name="item__2d_2dpermutetimelimit_3d_3carg_3e_2c__2dp_3carg_3"><strong>--permutetimelimit=&lt;arg</strong>, -<strong>P</strong>&lt;arg&gt; &gt;&gt;&gt;</a></strong></dt>

<dd>
<p>Upper time limit upto which fixing of subsumed specifications is done.
I.e. if a specification suggested by the adviser is subsumed, and
the suggested timelimit is less or equal to permutetimelimit, then
the specification will be fixed by adding additional axioms
in order of their relevance.
Default is equal to mincpulimit. If 0, no fixing is done.</p>
</dd>
<dt><strong><a name="item__2d_2ddofull_3d_3carg_3e_2c__2df_3carg_3e"><strong>--dofull=&lt;arg</strong>, -f&lt;arg&gt; &gt;&gt;&gt;</a></strong></dt>

<dd>
<p>If 1, the first pass is a max-timelimit run on full problems. 
If 2, the first pass is a min-timelimit run on full problems. 
If 0, that pass is omitted, and the symbol-only pass is the first run.
Default is 1.</p>
</dd>
<dt><strong><a name="item__2d_2diterrecover_3d_3carg_3e_2c__2di_3carg_3e"><strong>--iterrecover=&lt;arg</strong>, -<strong>I</strong>&lt;arg&gt; &gt;&gt;&gt;</a></strong></dt>

<dd>
<p>Instead of starting fresh, assume that iteration passed as arg
was already done. Load the result table and all other needed
tables, and continue with the next iteration.</p>
</dd>
<dt><strong><a name="item__2d_2dloadprovedby_3d_3carg_3e_2c__2db_3carg_3e"><strong>--loadprovedby=&lt;arg</strong>, -<strong>B</strong>&lt;arg&gt; &gt;&gt;&gt;</a></strong></dt>

<dd>
<p>Load the initial proved_by table from the given file.
Otherwise, the default initial proved_by table contains for each formulas
the info that it can be proved by itself (this initializes the learning).
If an entry for some formula is missing in the given file,
the default info will be added for it.</p>
</dd>
<dt><strong><a name="item__2d_2druneprover_3d_3carg_3e_2c__2de_3carg_3e"><strong>--runeprover=&lt;arg</strong>, -<strong>E</strong>&lt;arg&gt; &gt;&gt;&gt;</a></strong></dt>

<dd>
<p>If &gt;= 1, run E. Default is 1.
If greater than 1, run only in passes where the number
of refs is not greater than this.</p>
</dd>
<dt><strong><a name="item__2d_2drunspass_3d_3carg_3e_2c__2ds_3carg_3e"><strong>--runspass=&lt;arg</strong>, -<strong>S</strong>&lt;arg&gt; &gt;&gt;&gt;</a></strong></dt>

<dd>
<p>If &gt;= 1, run SPASS. Default is 1.
If greater than 1, run only in passes where the number
of refs is not greater than this.</p>
</dd>
<dt><strong><a name="item__2d_2drunvampire_3d_3carg_3e_2c__2dv_3carg_3e"><strong>--runvampire=&lt;arg</strong>, -<strong>V</strong>&lt;arg&gt; &gt;&gt;&gt;</a></strong></dt>

<dd>
<p>If &gt;= 1, run Vampire. Default is 0.
If greater than 1, run only in passes where the number
of refs is not greater than this.</p>
</dd>
<dt><strong><a name="item__2d_2drunparadox_3d_3carg_3e_2c__2dp_3carg_3e"><strong>--runparadox=&lt;arg</strong>, -<strong>p</strong>&lt;arg&gt; &gt;&gt;&gt;</a></strong></dt>

<dd>
<p>If &gt;= 1, run Paradox. Default is 0.
If greater than 1, run only in passes where the number
of refs is not greater than this. Good nonzero default
is then 128.</p>
</dd>
<dt><strong><a name="item__2d_2drunmace_3d_3carg_3e_2c__2dm_3carg_3e"><strong>--runmace=&lt;arg</strong>, -<strong>M</strong>&lt;arg&gt; &gt;&gt;&gt;</a></strong></dt>

<dd>
<p>If &gt;= 1, and running Paradox, run also Mace to construct a model.
If greater than 1, run only in passes where the number
of refs is not greater than this.
The model is then used for evaluation of formulas. Default is 64,
because this is constraint by --runparadox anyway.</p>
</dd>
<dt><strong><a name="item__2d_2dusemodels_3d_3carg_3e_2c__2dd_3carg_3e"><strong>--usemodels=&lt;arg</strong>, -<strong>D</strong>&lt;arg&gt; &gt;&gt;&gt;</a></strong></dt>

<dd>
<p>Use models for learning relevance of formulas. If 1, only negative
models are used, if 2, only positive models are used, if 3,
both positive and negative models are used, if 0, none are used.
Default is 1. This asssumes --runmace=1.</p>
</dd>
<dt><strong><a name="item__2d_2dsrassemul_3d_3carg_3e_2c__2dr_3carg_3e"><strong>--srassemul=&lt;arg</strong>, -<strong>R</strong>&lt;arg&gt; &gt;&gt;&gt;</a></strong></dt>

<dd>
<p>If 1, and running Mace (i.e. models are used), try to extend problem
specifications using the SRASS algorithm. That is: axioms that were
evaluated as false in some model of the negated conjecture are
greedily added (in order of their relevance) until all such models
are covered (or we run out of falsifying axioms).
Default is 1, because this is constraint by --runmace anyway.</p>
</dd>
<dt><strong><a name="item__2d_2dsimilarity_3d_3carg_3e_2c__2di_3carg_3e"><strong>--similarity=&lt;arg</strong>, -i&lt;arg&gt; &gt;&gt;&gt;</a></strong></dt>

<dd>
<p>The similarity measure for formulas. If 1, only vector of symbols
is used, if 2, only codes of shared terms are used, if 4, the shared terms
are first normalized by renaming all variables to just one generic variable.
Combinations of these basic methods can be done by summing their codes
(i.e., value 7 would tell to use all of them).
Default is 1 (symbols only).</p>
</dd>
<dt><strong><a name="item__2d_2dgeneralize_3d_3carg_3e_2c__2dg_3carg_3e"><strong>--generalize=&lt;arg</strong>, -g&lt;arg&gt; &gt;&gt;&gt;</a></strong></dt>

<dd>
<p>The generalization method for formulas. If 0, no generalization is done.
If 1, new generalized formulas are created by replacing all local constants
in formulas with a new special symbol. The generalized formulas
become learning targets exactly as the original ones, and they are included
into training whenever some corresponding original formula is. Accordingly,
when a generalized fla is recommended by the trained system as an axiom,
the corresponding original flas become recommended.
Default is 0.</p>
</dd>
<dt><strong><a name="item__2d_2dparallelize_3d_3carg_3e_2c__2dj_3carg_3e"><strong>--parallelize=&lt;arg</strong>, -j&lt;arg&gt; &gt;&gt;&gt;</a></strong></dt>

<dd>
<p>If greater than 1, runs problems in parallel, using Makefile with
the -j&lt;arg&gt; option. Currently works only with E.
Default is 1 - no parallelization.</p>
</dd>
<dt><strong><a name="item__2d_2diterpolicy_3d_3carg_3e_2c__2dy_3carg_3e"><strong>--iterpolicy=&lt;arg</strong>, -y&lt;arg&gt; &gt;&gt;&gt;</a></strong></dt>

<dd>
<p>Policy for iterations. Default is 0 - the standard learning greedy,
minimal axioms loop. Another implemented option is 1: prefers
to grow the axiomlimit to the maximum regardless of previous
success, and only when it is maximal, it drops to the lowest value.</p>
</dd>
<dt><strong><a name="item__2d_2drecadvice_3d_3carg_3e_2c__2da_3carg_3e"><strong>--recadvice=&lt;arg</strong>, -a&lt;arg&gt; &gt;&gt;&gt;</a></strong></dt>

<dd>
<p>If nonzero, the axiom advising phase is repeated this many times,
recursively using the recommended axioms to enlarge the set of symbols
for the next advising phase. Default is 0 (no recursion).</p>
</dd>
<dt><strong><a name="item__2d_2dreuseeval_3d_3carg_3e_2c__2du_3carg_3e"><strong>--reuseeval=&lt;arg</strong>, -u&lt;arg&gt; &gt;&gt;&gt;</a></strong></dt>

<dd>
<p>If nonzero, the evaluation of the learner is stored after each pass
(can be a huge file), and if nothing new was proved in the previous
pass, it is re-used (instead of running the same evaluation).
The current implementation will conflict with the modelinfo features,
so don't use it if usemodels is on.
Default is 0 (no re-use, still experimental).</p>
</dd>
<dt><strong><a name="item__2d_2dlimittargets_3d_3carg_3e_2c__2dl_3carg_3e"><strong>--limittargets=&lt;arg</strong>, -<strong>L</strong>&lt;arg&gt; &gt;&gt;&gt;</a></strong></dt>

<dd>
<p>If nonzero, it is the maximum number of targets that the
machine learner prints for further consideration. This can
be a useful speed-up when the number of targets is very high
(say 100000), but we only need a small number of them that
are very likely to be recommended within a much smaller initial
segment. Default is 0 - no limit. A useful limit is 1000.</p>
</dd>
<dt><strong><a name="item__2d_2dboostlimit_3d_3carg_3e_2c__2db_3carg_3e"><strong>--boostlimit=&lt;arg</strong>, -b&lt;arg&gt; &gt;&gt;&gt;</a></strong></dt>

<dd>
<p>If nonzero, the axioms in small specifications are slightly
boosted in learning by the boostweight/100. A specification is
small, if it has less axioms than (boostlimit/100) * number-of-all-axioms.
Default is 0 (no boosting). A reasonable boosting default is 1,
i.e. with 70000 total axioms in all specs, axioms in those
with less than 700 will be boosted. The idea is that this will
help to focus in the much larger specifications, in the same way
as the info about proof helps.</p>
</dd>
<dt><strong><a name="item__2d_2dboostweight_3d_3carg_3e_2c__2dw_3carg_3e"><strong>--boostweight=&lt;arg</strong>, -w&lt;arg&gt; &gt;&gt;&gt;</a></strong></dt>

<dd>
<p>The weight used for boosting if boostlimit &gt; 0. This
is negated and exponentiated to get the boost factor. The default
is 7 (so the boost factor is exp -7 = ca. 0.01), because this is
constraint by boostlimit anyway.</p>
</dd>
<dt><strong><a name="item__2d_2drefsbgcheat_3d_3carg_3e_2c__2dr_3carg_3e"><strong>--refsbgcheat=&lt;arg</strong>, -r&lt;arg&gt; &gt;&gt;&gt;</a></strong></dt>

<dd>
<p>Tells to cheat by limiting background for problems
whose subproblems (specified in .refspec) are solved.
Useful for reproving. Default is 0 - no cheating.</p>
</dd>
<dt><strong><a name="item__2d_2dalwaysmizrefs_3d_3carg_3e_2c__2dm_3carg_3e"><strong>--alwaysmizrefs=&lt;arg</strong>, -m&lt;arg&gt; &gt;&gt;&gt;</a></strong></dt>

<dd>
<p>If 1, tells to always include the explicit Mizar references. This
is useful for the bushy problems, where we are reasonably sure
that the explicit Mizar references should be used in the proof,
while we are uncertain about the background formulas.
The explicit references are now recongized by matching the regexp
``^[tldes][0-9]+'' (for theorems, top-level lemmas, definitions,
sublemmas, and scheme instances).
If 2, references containing Mizar local constants are always
included. These references are recognized by grepping
for ``\bc[0-9]+'' in the formula symbols.</p>
</dd>
<dt><strong><a name="item__2d_2dhelp_2c__2dh"><strong>--help, -h </strong>&gt;&gt;</a></strong></dt>

<dd>
<p>Print a brief help message and exit.</p>
</dd>
<dt><strong><a name="item__2d_2dman"><strong>--man </strong>&gt;&gt;</a></strong></dt>

<dd>
<p>Print the manual page and exit.</p>
</dd>
</dl>
<p>
</p>
<hr />
<h1><a name="description">DESCRIPTION</a></h1>
<p>Josef Urban: MaLARea: a Metasystem for Automated Reasoning in Large Theories.
Proceedings of the CADE-21 Workshop on
Empirically Successful Automated Reasoning in Large Theories
Bremen, Germany, 17th July 2007.
<a href="http://ftp.informatik.rwth-aachen.de/Publications/CEUR-WS/Vol-257/05_Urban.pdf">http://ftp.informatik.rwth-aachen.de/Publications/CEUR-WS/Vol-257/05_Urban.pdf</a> .</p>
<p>Urban J., Sutcliffe G., Pudlak P., Vyskocil J. (2007),
MaLARea SG1: Machine Learner for Automated Reasoning with Semantic Guidance,
In Baumgartner P., Armando A., Gilles D.,
Proceedings of the 4th International Joint Conference on Automated Reasoning (Sydney, Australia),
Lecture Notes in Artificial Intelligence (To appear).
<a href="http://kti.mff.cuni.cz/~urban/MaLAReaSG1.pdf">http://kti.mff.cuni.cz/~urban/MaLAReaSG1.pdf</a> .</p>
<p>
</p>
<hr />
<h1><a name="contact">CONTACT</a></h1>
<p>Josef Urban <a href="mailto:urban@kti.ms.mff.cuni.cz">urban@kti.ms.mff.cuni.cz</a></p>
<p>
</p>
<hr />
<h1><a name="licence">LICENCE</a></h1>
<p>This program is free software; you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation; either version 2 of the License, or
(at your option) any later version.</p>

</body>

</html>
